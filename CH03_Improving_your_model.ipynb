{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH03_Improving-your-model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scharnk/Machine-Learning-with-the-Experts/blob/master/CH03_Improving_your_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYkA8yOrTxDh",
        "colab_type": "text"
      },
      "source": [
        "# Pipeline workflow\n",
        "\n",
        "* repeatable way to go from raw data to trained model\n",
        "* pipeline object takes sequential list of steps\n",
        "** output of one step is input to next step\n",
        "* each step is a tuple of two elements\n",
        "** each has a name (string) and an object (implements .fit() & .transform())\n",
        "\n",
        "\n",
        "* 'imp' imputer - mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brg9ifP-SzD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Import other necessary modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Split and select numeric data only, no nans \n",
        "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n",
        "                                                    pd.get_dummies(sample_df['label']), \n",
        "                                                    random_state=22)\n",
        "\n",
        "# Instantiate Pipeline object: pl\n",
        "pl = Pipeline([\n",
        "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
        "    ])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4_Tove8byTn",
        "colab_type": "text"
      },
      "source": [
        "### Imputer step should always come before the classifier step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RmMPiiObX8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Imputer object\n",
        "from sklearn.preprocessing import Imputer\n",
        "\n",
        "# Create training and test sets using only numeric data\n",
        "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
        "                                                    pd.get_dummies(sample_df['label']), \n",
        "                                                    random_state=456)\n",
        "\n",
        "# Insantiate Pipeline object: pl\n",
        "pl = Pipeline([\n",
        "        ('imp', Imputer()),\n",
        "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
        "    ])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSOlrkypcK48",
        "colab_type": "text"
      },
      "source": [
        "* just used preprocessing in a pipeline with numeric data, and the accuracy improved because of it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyOn6v1_cWhD",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing multiple dtypes\n",
        "\n",
        "### Problem:\n",
        "\n",
        "Pipeline steps from string and numeric preprocessing can't follow one another\n",
        "\n",
        "### Solution:\n",
        "\n",
        "FunctionTransformer() & FeatureUnion()\n",
        "\n",
        "\n",
        "## FunctionTransformer()\n",
        "* write two functions for pipeline preprocessing\n",
        "** from entire DataFrame, return numeric columns\n",
        "** from entire DataFrame, return text columns\n",
        "* Can then process text and numeric data in separate pipelines\n",
        "\n",
        "## FeautureUnion()\n",
        "* combines the numeric features with the text features, to then be sent to the classifier as a single unit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20xew7i-g9XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Split out only the text data\n",
        "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
        "                                                    pd.get_dummies(sample_df['label']), \n",
        "                                                    random_state=456)\n",
        "\n",
        "# Instantiate Pipeline object: pl\n",
        "pl = Pipeline([\n",
        "        ('vec', CountVectorizer()),\n",
        "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
        "    ])\n",
        "\n",
        "# Fit to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on sample data - just text data: \", accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvJQraMlg-Le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import FunctionTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Obtain the text data: get_text_data\n",
        "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
        "\n",
        "# Obtain the numeric data: get_numeric_data\n",
        "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
        "\n",
        "# Fit and transform the text data: just_text_data\n",
        "just_text_data = get_text_data.fit_transform(sample_df)\n",
        "\n",
        "# Fit and transform the numeric data: just_numeric_data\n",
        "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
        "\n",
        "# Print head to check results\n",
        "print('Text Data')\n",
        "print(just_text_data.head())\n",
        "print('\\nNumeric Data')\n",
        "print(just_numeric_data.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cr8G_JVisZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import FeatureUnion\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "# Split using ALL data in sample_df\n",
        "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
        "                                                    pd.get_dummies(sample_df['label']), \n",
        "                                                    random_state=22)\n",
        "\n",
        "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
        "process_and_join_features = FeatureUnion(\n",
        "            transformer_list = [\n",
        "                ('numeric_features', Pipeline([\n",
        "                    ('selector', get_numeric_data),\n",
        "                    ('imputer', Imputer())\n",
        "                ])),\n",
        "                ('text_features', Pipeline([\n",
        "                    ('selector', get_text_data),\n",
        "                    ('vectorizer', CountVectorizer())\n",
        "                ]))\n",
        "             ]\n",
        "        )\n",
        "\n",
        "# Instantiate nested pipeline: pl\n",
        "pl = Pipeline([\n",
        "        ('union', process_and_join_features),\n",
        "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
        "    ])\n",
        "\n",
        "\n",
        "# Fit pl to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on sample data - all data: \", accuracy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_QjyrctkvWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import FunctionTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "# Get the dummy encoding of the labels\n",
        "dummy_labels = pd.get_dummies(df[LABELS])\n",
        "\n",
        "# Get the columns that are features in the original df\n",
        "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
        "                                                               dummy_labels,\n",
        "                                                               0.2, \n",
        "                                                               seed=123)\n",
        "\n",
        "# Preprocess the text data: get_text_data\n",
        "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
        "\n",
        "# Preprocess the numeric data: get_numeric_data\n",
        "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvKj3YWXlNis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Complete the pipeline: pl\n",
        "pl = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "            transformer_list = [\n",
        "                ('numeric_features', Pipeline([\n",
        "                    ('selector', get_numeric_data),\n",
        "                    ('imputer', Imputer())\n",
        "                ])),\n",
        "                ('text_features', Pipeline([\n",
        "                    ('selector', get_text_data),\n",
        "                    ('vectorizer', CountVectorizer())\n",
        "                ]))\n",
        "             ]\n",
        "        )),\n",
        "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
        "    ])\n",
        "\n",
        "# Fit to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on budget dataset: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBR-mdGLlfwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import random forest classifer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Edit model step in pipeline\n",
        "pl = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "            transformer_list = [\n",
        "                ('numeric_features', Pipeline([\n",
        "                    ('selector', get_numeric_data),\n",
        "                    ('imputer', Imputer())\n",
        "                ])),\n",
        "                ('text_features', Pipeline([\n",
        "                    ('selector', get_text_data),\n",
        "                    ('vectorizer', CountVectorizer())\n",
        "                ]))\n",
        "             ]\n",
        "        )),\n",
        "        ('clf', RandomForestClassifier())\n",
        "    ])\n",
        "\n",
        "# Fit to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on budget dataset: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx8fjcFzmVC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Add model step to pipeline: pl\n",
        "pl = Pipeline([\n",
        "        ('union', FeatureUnion(\n",
        "            transformer_list = [\n",
        "                ('numeric_features', Pipeline([\n",
        "                    ('selector', get_numeric_data),\n",
        "                    ('imputer', Imputer())\n",
        "                ])),\n",
        "                ('text_features', Pipeline([\n",
        "                    ('selector', get_text_data),\n",
        "                    ('vectorizer', CountVectorizer())\n",
        "                ]))\n",
        "             ]\n",
        "        )),\n",
        "        ('clf', RandomForestClassifier(n_estimators=15))\n",
        "    ])\n",
        "\n",
        "# Fit to the training data\n",
        "pl.fit(X_train, y_train)\n",
        "\n",
        "# Compute and print accuracy\n",
        "accuracy = pl.score(X_test, y_test)\n",
        "print(\"\\nAccuracy on budget dataset: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}